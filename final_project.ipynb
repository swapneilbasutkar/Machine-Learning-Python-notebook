{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swapn\\AppData\\Local\\Temp\\ipykernel_14420\\1633124903.py:14: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack categories: attack_category\n",
      "Benign                 562335\n",
      "Background             170151\n",
      "Probing                 23388\n",
      "Bruteforce-XML           8795\n",
      "Bruteforce               7988\n",
      "XMRIGCC CryptoMiner      7595\n",
      "Name: count, dtype: int64\n",
      "Columns with missings values: []\n",
      "Categorical variables\n",
      "['attack_category']\n",
      "Accuracy:  1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    112433\n",
      "           1       1.00      1.00      1.00      9572\n",
      "           2       1.00      1.00      1.00     34046\n",
      "\n",
      "    accuracy                           1.00    156051\n",
      "   macro avg       1.00      1.00      1.00    156051\n",
      "weighted avg       1.00      1.00      1.00    156051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code does the following:\n",
    "    1. Drops the unwanted columns which are object type and don't have a real impact on the model\n",
    "    2. Combines 2 dataset captured over the span of 2 years\n",
    "    3. 'attack category' column has 5 types of attack and 1 is benign category. Attacks are classified as either 1 or 2 and \n",
    "        benign is classified as 0.\n",
    "    4. One hot encoder is used and columns are segregated based on attack types.\n",
    "    5. Random forest model is run the get the accuracy. (Approx 80 features)\n",
    "\n",
    "Results:\n",
    "    We get almost perfect accuracy. This includes all the 80 features.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df1 = pd.read_csv('Datasets\\\\ALLFLOWMETER_HIKARI2021.csv')\n",
    "df2 = pd.read_csv('Datasets\\\\ALLFLOWMETER_HIKARI2022.csv')\n",
    "\n",
    "#df1.drop('bwd_last_window_size', axis=1)\n",
    "\n",
    "# Combining two IDS datasets acquired over 2 years to develop good model\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# we remove the 'flow_duration' here too because it has no real impact on the analysis and the formats are very different from same\n",
    "# synthetic dataset reproduced as shown in paper.\n",
    "combined_df = combined_df.drop(['Unnamed: 0', 'uid', 'flow_duration','bwd_last_window_size'], axis=1)\n",
    "\n",
    "combined_df['attack_category'] = combined_df['attack_category'].str.strip()\n",
    "# Replacing similar values with correct version\n",
    "combined_df['attack_category']=combined_df['attack_category'].replace('Brutefoce', 'Bruteforce')\n",
    "\n",
    "attack_category_counts = combined_df['attack_category'].value_counts()\n",
    "print(\"Attack categories:\",attack_category_counts)\n",
    "\n",
    "y = combined_df['Label']\n",
    "\n",
    "X = combined_df.drop(['Label', 'originh', 'responh'], axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Names of columns with missing values\n",
    "cols_with_missing_values = [col for col in X_train.columns\n",
    "                            if X_train[col].isnull().any()]\n",
    "\n",
    "print(\"Columns with missings values:\",cols_with_missing_values)\n",
    "# With prelimnary analysis we found that there were no missing values in any \n",
    "# of the columns. Hence, it is a robust dataset.\n",
    "\n",
    "#getting list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "print(\"Categorical variables\")\n",
    "print(object_cols)\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Removing the categorical columns (will be replacing with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rfc_model.fit(OH_X_train, y_train)\n",
    "\n",
    "predictions = rfc_model.predict(OH_X_valid)\n",
    "\n",
    "accuracy = accuracy_score(y_valid, predictions)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.0234672764034752e-06\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(OH_X_train, y_train)\n",
    "\n",
    "xgb_predictions = xgb_model.predict(OH_X_valid)\n",
    "\n",
    "predictions = xgb_model.predict(OH_X_valid)\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-score (KFold): 0.9999967957069185\n",
      "Confusion Matrix:\n",
      " [[112468      0      0]\n",
      " [     0   9553      0]\n",
      " [     0      0  34030]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    112468\n",
      "           1       1.00      1.00      1.00      9553\n",
      "           2       1.00      1.00      1.00     34030\n",
      "\n",
      "    accuracy                           1.00    156051\n",
      "   macro avg       1.00      1.00      1.00    156051\n",
      "weighted avg       1.00      1.00      1.00    156051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df1 = pd.read_csv('Datasets\\\\ALLFLOWMETER_HIKARI2021.csv')\n",
    "df2 = pd.read_csv('Datasets\\\\ALLFLOWMETER_HIKARI2022.csv')\n",
    "\n",
    "#df1.drop('bwd_last_window_size', axis=1)\n",
    "\n",
    "# Combining two IDS datasets acquired over 2 years to develop good model\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# we remove the 'flow_duration' here too because it has no real impact on the analysis and the formats are very different from same\n",
    "# synthetic dataset reproduced as shown in paper.\n",
    "combined_df = combined_df.drop(['Unnamed: 0', 'uid', 'flow_duration','bwd_last_window_size'], axis=1)\n",
    "\n",
    "combined_df['attack_category'] = combined_df['attack_category'].str.strip()\n",
    "# Replacing similar values with correct version\n",
    "combined_df['attack_category']=combined_df['attack_category'].replace('Brutefoce', 'Bruteforce')\n",
    "\n",
    "\n",
    "X = combined_df.drop(['Label', 'originh', 'responh'], axis=1)\n",
    "y = combined_df['Label']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Removing the categorical columns (will be replacing with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([X_train.drop(object_cols, axis=1), OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([X_valid.drop(object_cols, axis=1), OH_cols_valid], axis=1)\n",
    "\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "\n",
    "# K-Fold Cross-Validation with F1-score evaluation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)  # 5-fold stratified cross-validation\n",
    "f1_scores = []\n",
    "for train_index, test_index in kfold.split(OH_X_train, y_train):\n",
    "  # Train on fold data\n",
    "  fold_train_x, fold_train_y = OH_X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "  rfc_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "  rfc_model.fit(fold_train_x, fold_train_y)\n",
    "\n",
    "  # Make predictions on validation fold data\n",
    "  fold_test_x, fold_test_y = OH_X_train.iloc[test_index], y_train.iloc[test_index]\n",
    "  predictions = rfc_model.predict(fold_test_x)\n",
    "\n",
    "  # Calculate F1-score\n",
    "  f1 = f1_score(fold_test_y, predictions, average='weighted')\n",
    "  f1_scores.append(f1)\n",
    "\n",
    "# Print average F1-score across folds\n",
    "print(\"Average F1-score (KFold):\", np.mean(f1_scores))\n",
    "\n",
    "# Confusion Matrix on validation set\n",
    "y_pred = rfc_model.predict(OH_X_valid)\n",
    "confusion_matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "\n",
    "# Classification Report on validation set (using F1-score)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-score (KFold): 1.0\n",
      "Confusion Matrix:\n",
      " [[112468      0      0]\n",
      " [     0   9553      0]\n",
      " [     0      0  34030]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    112468\n",
      "           1       1.00      1.00      1.00      9553\n",
      "           2       1.00      1.00      1.00     34030\n",
      "\n",
      "    accuracy                           1.00    156051\n",
      "   macro avg       1.00      1.00      1.00    156051\n",
      "weighted avg       1.00      1.00      1.00    156051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\"\"\"\n",
    "In the below code, we select only the top features that we got from chi-squared tests.\n",
    "Only the columns that are making lot of impact are included.\n",
    "Additionally, the columns named '0' to '5' are included because we get from One-Hot Encoder\n",
    "and they are essential for predicting.\n",
    "\"\"\"\n",
    "top_features = ['fwd_iat.min','fwd_iat.max', 'fwd_iat.tot', 'fwd_iat.avg', 'fwd_iat.std',\n",
    "                'bwd_iat.max', 'bwd_iat.tot', 'bwd_iat.avg', 'bwd_iat.std',\n",
    "                'flow_iat.min', 'flow_iat.max', 'flow_iat.tot', 'flow_iat.avg',\n",
    "                'flow_iat.std', 'payload_bytes_per_second',\n",
    "                'bwd_bulk_rate', 'active.min', 'active.max', 'active.tot', 'active.avg',\n",
    "                'active.std', 'idle.min', 'idle.max', 'idle.tot', 'idle.avg',\n",
    "                'idle.std','0','1','2','3','4','5'] \n",
    "\n",
    "X_train_top_features = OH_X_train[top_features]\n",
    "X_valid_top_features = OH_X_valid[top_features]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)  # 5-fold stratified cross-validation\n",
    "f1_scores = []\n",
    "for train_index, test_index in kfold.split(X_train_top_features, y_train):\n",
    "  # Train on fold data\n",
    "  fold_train_x, fold_train_y = X_train_top_features.iloc[train_index], y_train.iloc[train_index]\n",
    "  rfc_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "  rfc_model.fit(fold_train_x, fold_train_y)\n",
    "\n",
    "  # Make predictions on validation fold data\n",
    "  fold_test_x, fold_test_y = X_train_top_features.iloc[test_index], y_train.iloc[test_index]\n",
    "  predictions = rfc_model.predict(fold_test_x)\n",
    "\n",
    "  # Calculate F1-score\n",
    "  f1 = f1_score(fold_test_y, predictions, average='weighted')\n",
    "  f1_scores.append(f1)\n",
    "\n",
    "# Print average F1-score across folds\n",
    "print(\"Average F1-score (KFold):\", np.mean(f1_scores))\n",
    "\n",
    "# Confusion Matrix on validation set\n",
    "y_pred = rfc_model.predict(X_valid_top_features)\n",
    "y_valid_np = y_valid.to_numpy()\n",
    "confusion_matrix = confusion_matrix(y_valid_np, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "\n",
    "# Classification Report on validation set (using F1-score)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Initialize SVM classifier with optimized hyperparameters\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=0)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model.fit(X_train_top_features, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_svm = svm_model.predict(X_valid_top_features)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Support Vector Machine (SVM):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Layer Perceptron (MLP):\n",
      "Confusion Matrix:\n",
      " [[112468      0      0]\n",
      " [  8792    761      0]\n",
      " [ 19774      0  14256]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89    112468\n",
      "           1       1.00      0.08      0.15      9553\n",
      "           2       1.00      0.42      0.59     34030\n",
      "\n",
      "    accuracy                           0.82    156051\n",
      "   macro avg       0.93      0.50      0.54    156051\n",
      "weighted avg       0.85      0.82      0.78    156051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(200, 100), max_iter=1000, random_state=0)\n",
    "mlp_model.fit(X_train_top_features, y_train)\n",
    "\n",
    "y_pred_mlp = mlp_model.predict(X_valid_top_features)\n",
    "accuracy = accuracy_score(y_valid, y_pred_mlp)\n",
    "print(\"Multi-Layer Perceptron (MLP):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_mlp))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816944460464848\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with k=1: Accuracy = 0.8393, F1 Score = 0.8393\n",
      "KNN with k=2: Accuracy = 0.8735, F1 Score = 0.8610\n",
      "KNN with k=3: Accuracy = 0.8597, F1 Score = 0.8556\n",
      "KNN with k=4: Accuracy = 0.8740, F1 Score = 0.8626\n",
      "KNN with k=5: Accuracy = 0.8670, F1 Score = 0.8615\n",
      "KNN with k=6: Accuracy = 0.8741, F1 Score = 0.8633\n",
      "KNN with k=7: Accuracy = 0.8700, F1 Score = 0.8637\n",
      "KNN with k=8: Accuracy = 0.8741, F1 Score = 0.8636\n",
      "KNN with k=9: Accuracy = 0.8724, F1 Score = 0.8657\n",
      "KNN with k=10: Accuracy = 0.8738, F1 Score = 0.8635\n",
      "KNN with k=11: Accuracy = 0.8721, F1 Score = 0.8652\n",
      "KNN with k=12: Accuracy = 0.8733, F1 Score = 0.8632\n",
      "KNN with k=13: Accuracy = 0.8725, F1 Score = 0.8655\n",
      "KNN with k=14: Accuracy = 0.8729, F1 Score = 0.8630\n",
      "KNN with k=15: Accuracy = 0.8719, F1 Score = 0.8647\n",
      "KNN with k=16: Accuracy = 0.8728, F1 Score = 0.8630\n",
      "KNN with k=17: Accuracy = 0.8722, F1 Score = 0.8649\n",
      "KNN with k=18: Accuracy = 0.8721, F1 Score = 0.8622\n",
      "KNN with k=19: Accuracy = 0.8711, F1 Score = 0.8637\n",
      "KNN with k=20: Accuracy = 0.8714, F1 Score = 0.8617\n",
      "\n",
      "Best k value: 6\n",
      "Best Accuracy: 0.8741\n",
      "Best F1 Score: 0.8633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Define a range of k values\n",
    "k_values = range(1, 21)  # You can adjust the range as needed\n",
    "\n",
    "best_k = None\n",
    "best_accuracy = 0\n",
    "best_f1_score = 0\n",
    "\n",
    "# Iterate over each value of k\n",
    "for k in k_values:\n",
    "    # Train KNN model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train_top_features, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_pred_knn = knn_model.predict(X_valid_top_features)\n",
    "\n",
    "    # Evaluate KNN performance\n",
    "    accuracy = accuracy_score(y_valid, y_pred_knn)\n",
    "    f1 = f1_score(y_valid, y_pred_knn, average='weighted')\n",
    "\n",
    "    # Print performance metrics for each k value\n",
    "    print(f\"KNN with k={k}: Accuracy = {accuracy:.4f}, F1 Score = {f1:.4f}\")\n",
    "\n",
    "    # Update best_k if current model has higher accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_k = k\n",
    "        best_f1_score = f1\n",
    "\n",
    "# Print the best k value and corresponding metrics\n",
    "print(f\"\\nBest k value: {best_k}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best F1 Score: {best_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier:\n",
      "Confusion Matrix:\n",
      " [[112468      0      0]\n",
      " [     0   9553      0]\n",
      " [     0      0  34030]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    112468\n",
      "           1       1.00      1.00      1.00      9553\n",
      "           2       1.00      1.00      1.00     34030\n",
      "\n",
      "    accuracy                           1.00    156051\n",
      "   macro avg       1.00      1.00      1.00    156051\n",
      "weighted avg       1.00      1.00      1.00    156051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "xgb_model.fit(X_train_top_features, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_valid_top_features)\n",
    "\n",
    "# Evaluate XGBoost performance\n",
    "print(\"XGBoost Classifier:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
